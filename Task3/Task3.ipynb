{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03902291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bornexair/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe011fc4150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.manual_seed(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6138ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceacada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_key_value_map(data, categorical, target):\n",
    "    keys = data.groupby(categorical)[target].mean().index\n",
    "    values = data.groupby(categorical)[target].mean().tolist()\n",
    "    \n",
    "    key_value_map = {}\n",
    "\n",
    "    for k, v in zip(keys, values):\n",
    "        key_value_map[k] = v\n",
    "        \n",
    "    key_value_map['default'] = data[target].mean()\n",
    "        \n",
    "    return key_value_map\n",
    "\n",
    "def apply_mean_encoding(data_to_train, data_to_apply, categorical, target):\n",
    "    kv_map = build_key_value_map(data_to_train, categorical, target)\n",
    "    return data_to_apply[categorical].apply(lambda x: kv_map[x] if x in kv_map.keys() else kv_map['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a34ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d571584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# care ocean_proximity == island has only 5 values - can be problematic\n",
    "#\n",
    "# before we simply jump into the pytorch I suggest to do the following \n",
    "# 1) create OHE for ocean_proximity\n",
    "# 2) create mean encoding for ocean proximity\n",
    "# 3) use sklearn to \n",
    "#    a) split in train / test\n",
    "#    b) normalize and standardize the data\n",
    "# 4) jump into pytorch for some experiments\n",
    "#    a) vanilla MLP used in Task 1\n",
    "#    b) use AE to encode the features, then MLP on the features\n",
    "#    c) maybe something more exotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad66bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we gonna the caveman approach without pipelines etc for the simplicity\n",
    "\n",
    "proximity_ohe = pd.get_dummies(data['ocean_proximity'], prefix='op')\n",
    "data = pd.concat([data, proximity_ohe], axis=1)\n",
    "\n",
    "train_set = data.sample(int(0.7 * len(data)))\n",
    "test_set  = data[~data.index.isin(train_set.index)]\n",
    "\n",
    "# do not leak data through mean encoding, use training set only for key-value map\n",
    "train_set['mean_encoded'] = apply_mean_encoding(train_set, train_set, 'ocean_proximity', 'median_house_value')\n",
    "test_set['mean_encoded'] = apply_mean_encoding(train_set, test_set, 'ocean_proximity', 'median_house_value')\n",
    "\n",
    "train_set = train_set.drop('ocean_proximity', axis=1)\n",
    "test_set = test_set.drop('ocean_proximity', axis=1)\n",
    "\n",
    "\n",
    "target = 'median_house_value'\n",
    "X_train = train_set.drop(target, axis=1)\n",
    "y_train = train_set[target]\n",
    "X_test = test_set.drop(target, axis=1)\n",
    "y_test = test_set[target]\n",
    "\n",
    "SC = StandardScaler()\n",
    "\n",
    "X_train = SC.fit_transform(X_train)\n",
    "X_test = SC.fit_transform(X_test)\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "\n",
    "y_train = torch.Tensor(y_train)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c530a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c62c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SC.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb96d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = SC.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e091596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7196, -0.7418,  0.4983,  ..., -0.3530, -0.3861,  0.5918],\n",
       "        [ 0.5548, -0.7559,  0.0209,  ..., -0.3530, -0.3861,  0.5918],\n",
       "        [-1.9082,  1.5733, -0.0587,  ..., -0.3530, -0.3861,  0.5918],\n",
       "        ...,\n",
       "        [-0.4644,  1.5171, -1.4909,  ..., -0.3530, -0.3861, -1.4637],\n",
       "        [ 0.9245, -0.9480, -0.2178,  ..., -0.3530, -0.3861,  0.5918],\n",
       "        [ 0.3150, -0.6903, -2.0479,  ..., -0.3530, -0.3861,  0.5918]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a590b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_transformed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8499f6b2dff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_transformed_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_transformed_df' is not defined"
     ]
    }
   ],
   "source": [
    "X_transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528a323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240084.28546409807,\n",
       " 124805.39200122119,\n",
       " 380440.0,\n",
       " 259212.31179039303,\n",
       " 249433.97742663656]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('ocean_proximity')['median_house_value'].mean().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f958d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<1H OCEAN -- 240084.28546409807\n",
      "INLAND -- 124805.39200122119\n",
      "ISLAND -- 380440.0\n",
      "NEAR BAY -- 259212.31179039303\n",
      "NEAR OCEAN -- 249433.97742663656\n"
     ]
    }
   ],
   "source": [
    "keys = data.groupby('ocean_proximity')['median_house_value'].mean().index\n",
    "values = data.groupby('ocean_proximity')['median_house_value'].mean().tolist()\n",
    "\n",
    "for k, v in zip(keys, values):\n",
    "    print(f\"{k} -- {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596ba93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6774e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_map = build_key_value_map(data, 'ocean_proximity', 'median_house_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1257d2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        259212.311790\n",
       "1        259212.311790\n",
       "2        259212.311790\n",
       "3        259212.311790\n",
       "4        259212.311790\n",
       "             ...      \n",
       "20635    124805.392001\n",
       "20636    124805.392001\n",
       "20637    124805.392001\n",
       "20638    124805.392001\n",
       "20639    124805.392001\n",
       "Name: ocean_proximity, Length: 20640, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ocean_proximity'].apply(lambda x: kv_map[x] if x in kv_map.keys() else kv_map['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75532a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
